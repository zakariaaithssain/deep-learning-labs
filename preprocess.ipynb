{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "7162800f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "96bd1d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>dataset</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>typical angina</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>True</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>asymptomatic</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>non-anginal</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>False</td>\n",
       "      <td>normal</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>atypical angina</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>False</td>\n",
       "      <td>lv hypertrophy</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
       "0   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
       "1   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
       "2   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
       "3   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
       "4   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
       "\n",
       "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
       "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
       "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
       "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
       "3          normal   187.0  False      3.5  downsloping  0.0   \n",
       "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
       "\n",
       "                thal  num  \n",
       "0       fixed defect    0  \n",
       "1             normal    2  \n",
       "2  reversable defect    1  \n",
       "3             normal    0  \n",
       "4             normal    0  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/heart_disease_uci.csv\")\n",
    "data.drop(columns=[\"id\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "85c5a383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 15)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c62a93be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 920 entries, 0 to 919\n",
      "Data columns (total 15 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       920 non-null    int64  \n",
      " 1   sex       920 non-null    str    \n",
      " 2   dataset   920 non-null    str    \n",
      " 3   cp        920 non-null    str    \n",
      " 4   trestbps  861 non-null    float64\n",
      " 5   chol      890 non-null    float64\n",
      " 6   fbs       830 non-null    object \n",
      " 7   restecg   918 non-null    str    \n",
      " 8   thalch    865 non-null    float64\n",
      " 9   exang     865 non-null    object \n",
      " 10  oldpeak   858 non-null    float64\n",
      " 11  slope     611 non-null    str    \n",
      " 12  ca        309 non-null    float64\n",
      " 13  thal      434 non-null    str    \n",
      " 14  num       920 non-null    int64  \n",
      "dtypes: float64(5), int64(2), object(2), str(6)\n",
      "memory usage: 107.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c1eb7c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalch</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>920.000000</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.510870</td>\n",
       "      <td>132.132404</td>\n",
       "      <td>199.130337</td>\n",
       "      <td>137.545665</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.676375</td>\n",
       "      <td>0.995652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.424685</td>\n",
       "      <td>19.066070</td>\n",
       "      <td>110.780810</td>\n",
       "      <td>25.926276</td>\n",
       "      <td>1.091226</td>\n",
       "      <td>0.935653</td>\n",
       "      <td>1.142693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age    trestbps        chol      thalch     oldpeak          ca  \\\n",
       "count  920.000000  861.000000  890.000000  865.000000  858.000000  309.000000   \n",
       "mean    53.510870  132.132404  199.130337  137.545665    0.878788    0.676375   \n",
       "std      9.424685   19.066070  110.780810   25.926276    1.091226    0.935653   \n",
       "min     28.000000    0.000000    0.000000   60.000000   -2.600000    0.000000   \n",
       "25%     47.000000  120.000000  175.000000  120.000000    0.000000    0.000000   \n",
       "50%     54.000000  130.000000  223.000000  140.000000    0.500000    0.000000   \n",
       "75%     60.000000  140.000000  268.000000  157.000000    1.500000    1.000000   \n",
       "max     77.000000  200.000000  603.000000  202.000000    6.200000    3.000000   \n",
       "\n",
       "              num  \n",
       "count  920.000000  \n",
       "mean     0.995652  \n",
       "std      1.142693  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      2.000000  \n",
       "max      4.000000  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "80852fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "sex           0\n",
       "dataset       0\n",
       "cp            0\n",
       "trestbps     59\n",
       "chol         30\n",
       "fbs          90\n",
       "restecg       2\n",
       "thalch       55\n",
       "exang        55\n",
       "oldpeak      62\n",
       "slope       309\n",
       "ca          611\n",
       "thal        486\n",
       "num           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e35e35",
   "metadata": {},
   "source": [
    "stats: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8370b4",
   "metadata": {},
   "source": [
    "distribution of `num`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3cd229f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "0    411\n",
       "1    265\n",
       "2    109\n",
       "3    107\n",
       "4     28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"num\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de11ae",
   "metadata": {},
   "source": [
    "binarization of target variable (`num`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "03c2aac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num\n",
       "True     509\n",
       "False    411\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we don't copy we would modify original data and when running this cell alone we won't get what's intended\n",
    "binary_data = data.copy()\n",
    "binary_data[\"num\"] = binary_data[\"num\"] != 0\n",
    "binary_data[\"num\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949b55a",
   "metadata": {},
   "source": [
    "the dataset now became somehow balanced (509 vs 411)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc39edf",
   "metadata": {},
   "source": [
    "#### handling missing values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7bb946e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trestbps',\n",
       " 'chol',\n",
       " 'fbs',\n",
       " 'restecg',\n",
       " 'thalch',\n",
       " 'exang',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal']"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing_data = binary_data.columns[binary_data.isna().sum()>0]\n",
    "cols_with_missing_data.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a435d",
   "metadata": {},
   "source": [
    "first we will drop any duplicate records or that have **all** these columns missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "25f25b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_data = binary_data.drop_duplicates(ignore_index=True)\n",
    "binary_data = binary_data.dropna(subset=cols_with_missing_data, how=\"all\", ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe731e9",
   "metadata": {},
   "source": [
    "then we will drop any missing values that are less than 5% of the dataset. \n",
    "dropping is not recommended unless the data is Missing Completely At Random (MCAR), but if the pourcentage is less than 5% then it's okay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4bf25b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trestbps     6.427015\n",
       "chol         3.159041\n",
       "fbs          9.803922\n",
       "restecg      0.217865\n",
       "thalch       5.991285\n",
       "exang        5.991285\n",
       "oldpeak      6.753813\n",
       "slope       33.442266\n",
       "ca          66.339869\n",
       "thal        52.723312\n",
       "dtype: float64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_of_missing = binary_data[cols_with_missing_data].isna().sum()/len(binary_data)*100\n",
    "percentage_of_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3c3379ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chol', 'restecg']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_less_than_5_missing = cols_with_missing_data[percentage_of_missing < 5]\n",
    "cols_with_less_than_5_missing.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f202892a",
   "metadata": {},
   "source": [
    "these two columns have less than 5% of their data missing, so it's safe to just drop these records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "affaca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data records before dropping less than 5%:  918\n",
      "data records after dropping less than 5%:  887\n"
     ]
    }
   ],
   "source": [
    "print(\"data records before dropping less than 5%: \", binary_data.shape[0])\n",
    "binary_data = binary_data.dropna(subset=cols_with_less_than_5_missing, ignore_index=True)\n",
    "print(\"data records after dropping less than 5%: \", binary_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b229d05d",
   "metadata": {},
   "source": [
    "now we should handle columns with more than 5% missing data. \n",
    "I don't really know much about these medical measures, but I'll try to decide which are MCAR, MAR, and MNAR, then decide which imputation technique to use accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "249e8423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trestbps', 'fbs', 'thalch', 'exang', 'oldpeak', 'slope', 'ca', 'thal']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_missing = cols_with_missing_data[percentage_of_missing >= 5]\n",
    "remaining_missing.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "178d5615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trestbps</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalch</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145.0</td>\n",
       "      <td>True</td>\n",
       "      <td>150.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.3</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fixed defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160.0</td>\n",
       "      <td>False</td>\n",
       "      <td>108.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.5</td>\n",
       "      <td>flat</td>\n",
       "      <td>3.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120.0</td>\n",
       "      <td>False</td>\n",
       "      <td>129.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.6</td>\n",
       "      <td>flat</td>\n",
       "      <td>2.0</td>\n",
       "      <td>reversable defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>130.0</td>\n",
       "      <td>False</td>\n",
       "      <td>187.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.5</td>\n",
       "      <td>downsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130.0</td>\n",
       "      <td>False</td>\n",
       "      <td>172.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.4</td>\n",
       "      <td>upsloping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>127.0</td>\n",
       "      <td>True</td>\n",
       "      <td>154.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>122.0</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fixed defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>120.0</td>\n",
       "      <td>False</td>\n",
       "      <td>93.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>887 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trestbps    fbs  thalch  exang  oldpeak        slope   ca  \\\n",
       "0       145.0   True   150.0  False      2.3  downsloping  0.0   \n",
       "1       160.0  False   108.0   True      1.5         flat  3.0   \n",
       "2       120.0  False   129.0   True      2.6         flat  2.0   \n",
       "3       130.0  False   187.0  False      3.5  downsloping  0.0   \n",
       "4       130.0  False   172.0  False      1.4    upsloping  0.0   \n",
       "..        ...    ...     ...    ...      ...          ...  ...   \n",
       "882     127.0   True   154.0  False      0.0          NaN  NaN   \n",
       "883       NaN  False     NaN    NaN      NaN          NaN  NaN   \n",
       "884     122.0   True   100.0  False      0.0          NaN  NaN   \n",
       "885       NaN   True     NaN    NaN      NaN          NaN  NaN   \n",
       "886     120.0  False    93.0   True      0.0          NaN  NaN   \n",
       "\n",
       "                  thal  \n",
       "0         fixed defect  \n",
       "1               normal  \n",
       "2    reversable defect  \n",
       "3               normal  \n",
       "4               normal  \n",
       "..                 ...  \n",
       "882                NaN  \n",
       "883                NaN  \n",
       "884       fixed defect  \n",
       "885                NaN  \n",
       "886                NaN  \n",
       "\n",
       "[887 rows x 8 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_data[remaining_missing]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6364c",
   "metadata": {},
   "source": [
    "this in fact looks like Missing At Random data (distribution of missing data is related to the other variables). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22be697",
   "metadata": {},
   "source": [
    "we will use an iterative imputer over the numerical missing values, but before we should train test split to avoid any data leakage. (encoding before splitting also causes data leakage, so better split then encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b33374de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#necessary because IterativeImputer is still experimental\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9f759af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = binary_data.drop(columns=['num'])\n",
    "y = binary_data.num\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165d857",
   "metadata": {},
   "source": [
    "we separate categorical variables from numercial ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "88c507ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X_train.select_dtypes(include=[\"object\", \"str\"]).columns\n",
    "numerical_cols = X_train.select_dtypes(exclude=[\"object\", \"str\"]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97116d",
   "metadata": {},
   "source": [
    "now we create the pipelines of encoding and imputation:   \n",
    "- for categorical variables: we impute each variable using its own mode, then we encode.   \n",
    "- for numerical variables: we scale then impute using IterativeImputer (ML-based imputation).   \n",
    "\n",
    "**Note:** we should scale before using the imputer, because it's ML based.  \n",
    "\n",
    "**Note2:** after imputing, the mean and std will shift (they will not be 0 and 1 respectively) because of the new data added using imputation, but we don't need to rescale again, because our features are already of the same scale as we scaled before imputation. (it's about having the same scale through features not having 0 mean and 1 std). (however I will scale again that won't hurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c53e4b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipe = Pipeline(\n",
    "    [\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n",
    "    (\"encoder\", OneHotEncoder())\n",
    "    ]\n",
    ")\n",
    "\n",
    "numerical_pipe = Pipeline(\n",
    "    [    (\"scaler\", StandardScaler()),\n",
    "        (\"imputer\", IterativeImputer(random_state=42, max_iter=40, initial_strategy='median')),\n",
    "        (\"post_impute_scaler\", StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c604aa",
   "metadata": {},
   "source": [
    "wrap both of them in a ColumnTransformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9ef212fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "    (\"num\", numerical_pipe, numerical_cols), \n",
    "    (\"cat\", categorical_pipe, categorical_cols)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfde150",
   "metadata": {},
   "source": [
    "now we will transfrom our data and save it to be used to train and test the MLP: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f8e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.56589989e-18  7.84515847e-17 -1.73814888e-17 -8.45585943e-18\n",
      "  5.35537764e-17 -8.45585943e-18  2.07334274e-01  7.92665726e-01\n",
      "  3.38504937e-01  3.03244006e-01  1.28349788e-01  2.29901269e-01\n",
      "  5.47249647e-01  1.94640339e-01  2.12976023e-01  4.51339915e-02\n",
      "  8.57545839e-01  1.42454161e-01  2.10155148e-01  5.90973202e-01\n",
      "  1.98871650e-01  6.17771509e-01  3.82228491e-01  7.33427362e-02\n",
      "  6.99576869e-01  2.27080395e-01  4.51339915e-02  7.43300423e-01\n",
      "  2.11565585e-01]\n"
     ]
    }
   ],
   "source": [
    "#we fit over the training data\n",
    "X_train_ready = preprocessor.fit_transform(X_train)\n",
    "# we should not re-fit over testing data to avoid data leakage\n",
    "X_test_ready = preprocessor.transform(X_test)\n",
    "# encode target variable: \n",
    "y_train = np.array(y_train.astype(int))\n",
    "y_test = np.array(y_test.astype(int))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299cae92",
   "metadata": {},
   "source": [
    "save them directly as `.joblib`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3f481bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/ready/ready.joblib']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "ready = {\"train\": {\n",
    "            \"X\": X_train_ready, \n",
    "            \"y\": y_train\n",
    "            }, \n",
    "        \"test\": {\n",
    "            \"X\": X_test_ready, \n",
    "            \"y\": y_test\n",
    "        }}\n",
    "\n",
    "os.makedirs(\"data/ready\", exist_ok=True)\n",
    "joblib.dump(ready, \"data/ready/ready.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
